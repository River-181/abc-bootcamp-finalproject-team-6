{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0ee24d",
   "metadata": {},
   "source": [
    "# 고객 이탈 예측 모델 - 평가 및 해석\n",
    "\n",
    "이 노트북에서는 학습된 모델의 성능을 상세히 평가하고, 비즈니스 관점에서 모델을 해석해보겠습니다.\n",
    "\n",
    "## 주요 내용\n",
    "1. **모델 로드 및 설정**: 저장된 최적 모델 불러오기\n",
    "2. **상세 성능 평가**: 다양한 메트릭을 통한 포괄적 평가\n",
    "3. **모델 해석**: 피처 중요도 및 예측 근거 분석\n",
    "4. **비즈니스 임팩트**: 실제 비즈니스 관점에서의 모델 가치 평가\n",
    "5. **배포 권장사항**: 모델 운영을 위한 실용적 가이드\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5910e55",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609e390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 라이브러리 로드 완료!\n",
      "🕐 평가 시작 시간: 2025-08-03 19:23:05\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정 (맥용)\n",
    "plt.rcParams['font.family'] = ['AppleGothic'] if os.name == 'posix' else ['Malgun Gothic']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 표시 옵션\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"📚 라이브러리 로드 완료!\")\n",
    "print(f\"🕐 평가 시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81446c27",
   "metadata": {},
   "source": [
    "## 2. 모델 및 데이터 로드\n",
    "\n",
    "03_Modeling.ipynb에서 저장한 최적 모델과 전처리된 데이터를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f0bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 모델 및 데이터 로딩 시작...\n",
      "📁 모델 파일 발견: best_model_gradient_boosting_20250803_191441.pkl\n",
      "✅ 모델 로드 완료: Gradient Boosting\n",
      "🔄 테스트 데이터 준비 중...\n",
      "📊 스케일링된 테스트 데이터 로드 중...\n",
      "⚠️ 누락값 1개 발견 - 처리 중...\n",
      "✅ 누락값 처리 완료\n",
      "📊 데이터 로드 완료 - 샘플 수: 750, 피처 수: 65\n",
      "🎯 예측 수행 중...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 65 features, but GradientBoostingClassifier is expecting 28 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# 예측 수행\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🎯 예측 수행 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    117\u001b[39m     y_pred_proba = model.predict_proba(X_test.values)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/abc-bootcamp-FP-2025/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:1627\u001b[39m, in \u001b[36mGradientBoostingClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1613\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[32m   1614\u001b[39m \n\u001b[32m   1615\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1625\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m   1626\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1627\u001b[39m     raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1628\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.ndim == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# decision_function already squeezed it\u001b[39;00m\n\u001b[32m   1629\u001b[39m         encoded_classes = (raw_predictions >= \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/abc-bootcamp-FP-2025/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:1580\u001b[39m, in \u001b[36mGradientBoostingClassifier.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1562\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[32m   1563\u001b[39m \n\u001b[32m   1564\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1578\u001b[39m \u001b[33;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[32m   1579\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1581\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1582\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1583\u001b[39m     raw_predictions = \u001b[38;5;28mself\u001b[39m._raw_predict(X)\n\u001b[32m   1584\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/abc-bootcamp-FP-2025/lib/python3.12/site-packages/sklearn/utils/validation.py:2975\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2975\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/abc-bootcamp-FP-2025/lib/python3.12/site-packages/sklearn/utils/validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 65 features, but GradientBoostingClassifier is expecting 28 features as input."
     ]
    }
   ],
   "source": [
    "# 저장된 모델 파일 찾기\n",
    "models_dir = '../results/models'\n",
    "data_dir = '../data/processed'\n",
    "\n",
    "print(\"🔄 모델 및 데이터 로딩 시작...\")\n",
    "\n",
    "# 모델 파일 확인\n",
    "if os.path.exists(models_dir):\n",
    "    model_files = [f for f in os.listdir(models_dir) if f.startswith('best_model_') and f.endswith('.pkl')]\n",
    "else:\n",
    "    model_files = []\n",
    "\n",
    "if not model_files:\n",
    "    print(\"⚠️ 저장된 모델이 없습니다. 03_Modeling.ipynb를 먼저 실행해주세요.\")\n",
    "    print(\"📝 샘플 데이터로 평가를 진행합니다...\")\n",
    "    \n",
    "    # 샘플 데이터 생성\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    X_test = pd.DataFrame({\n",
    "        'feature_1': np.random.normal(0, 1, n_samples),\n",
    "        'feature_2': np.random.normal(0, 1, n_samples),\n",
    "        'feature_3': np.random.normal(0, 1, n_samples),\n",
    "        'feature_4': np.random.normal(0, 1, n_samples),\n",
    "        'feature_5': np.random.normal(0, 1, n_samples)\n",
    "    })\n",
    "    \n",
    "    y_test = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "    y_pred = np.random.choice([0, 1], n_samples, p=[0.75, 0.25])\n",
    "    y_pred_proba = np.random.beta(2, 5, n_samples)\n",
    "    \n",
    "    model_info = {\n",
    "        'model_name': 'Sample Random Forest',\n",
    "        'performance': {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'auc': roc_auc_score(y_test, y_pred_proba)\n",
    "        },\n",
    "        'feature_names': list(X_test.columns),\n",
    "        'training_date': datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    }\n",
    "    \n",
    "    print(\"✅ 샘플 데이터 생성 완료\")\n",
    "    \n",
    "else:\n",
    "    # 가장 최근 모델 파일 선택\n",
    "    latest_model_file = max(model_files, key=lambda f: os.path.getctime(os.path.join(models_dir, f)))\n",
    "    print(f\"📁 모델 파일 발견: {latest_model_file}\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model_path = os.path.join(models_dir, latest_model_file)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # 모델 이름 추출\n",
    "    model_type = latest_model_file.split('_')[2]\n",
    "    model_name_mapping = {\n",
    "        'gradient': 'Gradient Boosting',\n",
    "        'random': 'Random Forest', \n",
    "        'xgb': 'XGBoost',\n",
    "        'logistic': 'Logistic Regression',\n",
    "        'svm': 'SVM',\n",
    "        'decision': 'Decision Tree',\n",
    "        'neural': 'Neural Network'\n",
    "    }\n",
    "    model_name = model_name_mapping.get(model_type, model_type.replace('_', ' ').title())\n",
    "    \n",
    "    # 타임스탬프 추출\n",
    "    timestamp = latest_model_file.split('_')[-1].replace('.pkl', '')\n",
    "    \n",
    "    # 모델 정보 설정\n",
    "    model_info = {\n",
    "        'model_name': model_name,\n",
    "        'performance': {},\n",
    "        'feature_names': [],\n",
    "        'training_date': timestamp\n",
    "    }\n",
    "    \n",
    "    print(f\"✅ 모델 로드 완료: {model_name}\")\n",
    "    \n",
    "    # 테스트 데이터 로드\n",
    "    print(\"🔄 테스트 데이터 준비 중...\")\n",
    "    \n",
    "    test_data_scaled_path = os.path.join(data_dir, 'test_data_scaled.csv')\n",
    "    \n",
    "    if os.path.exists(test_data_scaled_path):\n",
    "        print(\"📊 스케일링된 테스트 데이터 로드 중...\")\n",
    "        test_data = pd.read_csv(test_data_scaled_path)\n",
    "        \n",
    "        # NaN 값 처리\n",
    "        if test_data.isnull().sum().sum() > 0:\n",
    "            print(f\"⚠️ 누락값 {test_data.isnull().sum().sum()}개 발견 - 처리 중...\")\n",
    "            test_data = test_data.fillna(test_data.mean())\n",
    "            print(\"✅ 누락값 처리 완료\")\n",
    "        \n",
    "        # 피처와 타겟 분리\n",
    "        if 'churn' in test_data.columns:\n",
    "            X_test = test_data.drop(['churn'], axis=1)\n",
    "            y_test = test_data['churn'].values\n",
    "        else:\n",
    "            X_test = test_data\n",
    "            y_test = None\n",
    "        \n",
    "        # 모델 정보 업데이트\n",
    "        model_info['feature_names'] = list(X_test.columns)\n",
    "        \n",
    "        print(f\"📊 데이터 로드 완료 - 샘플 수: {len(X_test)}, 피처 수: {X_test.shape[1]}\")\n",
    "        \n",
    "        # 예측 수행\n",
    "        print(\"🎯 예측 수행 중...\")\n",
    "        y_pred = model.predict(X_test.values)\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_test.values)[:, 1]\n",
    "        else:\n",
    "            # 확률 예측이 불가능한 경우\n",
    "            if hasattr(model, 'decision_function'):\n",
    "                decision_scores = model.decision_function(X_test.values)\n",
    "                y_pred_proba = 1 / (1 + np.exp(-decision_scores))\n",
    "            else:\n",
    "                y_pred_proba = np.random.random(len(X_test))\n",
    "                print(\"⚠️ 확률 예측 불가 - 랜덤 확률 사용\")\n",
    "        \n",
    "        print(\"✅ 예측 완료\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ 테스트 데이터가 없어 샘플 데이터 생성...\")\n",
    "        np.random.seed(42)\n",
    "        n_samples = 500\n",
    "        n_features = 10\n",
    "        \n",
    "        X_test = pd.DataFrame(\n",
    "            np.random.normal(0, 1, (n_samples, n_features)),\n",
    "            columns=[f'feature_{i}' for i in range(n_features)]\n",
    "        )\n",
    "        y_test = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "        y_pred = model.predict(X_test.values)\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_test.values)[:, 1]\n",
    "        else:\n",
    "            y_pred_proba = np.random.random(n_samples)\n",
    "        \n",
    "        model_info['feature_names'] = list(X_test.columns)\n",
    "\n",
    "# 최종 정보 출력\n",
    "print(f\"\\n📋 평가 데이터 정보:\")\n",
    "print(f\"  • 모델: {model_info['model_name']}\")\n",
    "print(f\"  • 테스트 샘플 수: {len(X_test)}\")\n",
    "print(f\"  • 피처 수: {X_test.shape[1]}\")\n",
    "\n",
    "if y_test is not None:\n",
    "    print(f\"  • 이탈 고객 비율: {np.mean(y_test):.2%}\")\n",
    "    print(f\"  • 예측 이탈 비율: {np.mean(y_pred):.2%}\")\n",
    "else:\n",
    "    print(\"  • 실제 라벨 없음 (예측만 수행)\")\n",
    "\n",
    "print(\"\\n🎯 평가 준비 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb77e8",
   "metadata": {},
   "source": [
    "## 3. 상세 성능 평가\n",
    "\n",
    "다양한 평가 지표를 통해 모델의 성능을 종합적으로 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표 계산\n",
    "if y_test is not None:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    ap_score = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"🎯 {model_info['model_name']} 상세 성능 평가\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"📊 기본 분류 성능:\")\n",
    "    print(f\"  • Accuracy (정확도):     {accuracy:.4f}\")\n",
    "    print(f\"  • Precision (정밀도):    {precision:.4f}\")\n",
    "    print(f\"  • Recall (재현율):       {recall:.4f}\")\n",
    "    print(f\"  • F1-Score:             {f1:.4f}\")\n",
    "    print(f\"\\\\n📈 확률 기반 성능:\")\n",
    "    print(f\"  • ROC-AUC:              {auc:.4f}\")\n",
    "    print(f\"  • Average Precision:    {ap_score:.4f}\")\n",
    "    \n",
    "    # 혼동 행렬\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(f\"\\\\n🔍 혼동 행렬 분석:\")\n",
    "    print(f\"  • True Negatives (TN):   {tn:,} (올바른 비이탈 예측)\")\n",
    "    print(f\"  • False Positives (FP):  {fp:,} (잘못된 이탈 예측)\")\n",
    "    print(f\"  • False Negatives (FN):  {fn:,} (놓친 이탈 고객)\")\n",
    "    print(f\"  • True Positives (TP):   {tp:,} (올바른 이탈 예측)\")\n",
    "    \n",
    "    # 추가 지표\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"\\\\n📋 추가 성능 지표:\")\n",
    "    print(f\"  • Specificity (특이도):  {specificity:.4f}\")\n",
    "    print(f\"  • NPV (음성예측도):      {npv:.4f}\")\n",
    "    print(f\"  • False Positive Rate:  {fp/(fp+tn):.4f}\")\n",
    "    print(f\"  • False Negative Rate:  {fn/(fn+tp):.4f}\")\n",
    "    \n",
    "    # 분류 보고서\n",
    "    print(f\"\\\\n📑 상세 분류 보고서:\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                              target_names=['비이탈', '이탈'],\n",
    "                              digits=4))\n",
    "else:\n",
    "    print(\"⚠️ 실제 라벨이 없어 성능 평가를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc28735",
   "metadata": {},
   "source": [
    "## 4. 시각화 평가\n",
    "\n",
    "ROC 곡선, Precision-Recall 곡선, 혼동 행렬 등을 통한 시각적 평가를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_test is not None:\n",
    "    # 시각화 설정\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'{model_info[\"model_name\"]} - 모델 성능 시각화', fontsize=16, y=1.02)\n",
    "    \n",
    "    # 1. ROC 곡선\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    axes[0, 0].plot(fpr, tpr, linewidth=2, label=f'ROC (AUC = {auc:.3f})')\n",
    "    axes[0, 0].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random')\n",
    "    axes[0, 0].set_xlabel('False Positive Rate')\n",
    "    axes[0, 0].set_ylabel('True Positive Rate')\n",
    "    axes[0, 0].set_title('ROC Curve')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Precision-Recall 곡선\n",
    "    precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "    axes[0, 1].plot(recall_vals, precision_vals, linewidth=2, \n",
    "                   label=f'PR (AP = {ap_score:.3f})')\n",
    "    axes[0, 1].axhline(y=np.mean(y_test), color='k', linestyle='--', alpha=0.5, \n",
    "                      label=f'Baseline = {np.mean(y_test):.3f}')\n",
    "    axes[0, 1].set_xlabel('Recall')\n",
    "    axes[0, 1].set_ylabel('Precision')\n",
    "    axes[0, 1].set_title('Precision-Recall Curve')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 혼동 행렬 히트맵\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['비이탈', '이탈'],\n",
    "                yticklabels=['비이탈', '이탈'],\n",
    "                ax=axes[0, 2])\n",
    "    axes[0, 2].set_title('Confusion Matrix')\n",
    "    axes[0, 2].set_xlabel('Predicted')\n",
    "    axes[0, 2].set_ylabel('Actual')\n",
    "    \n",
    "    # 4. 예측 확률 분포\n",
    "    axes[1, 0].hist(y_pred_proba[y_test == 0], bins=30, alpha=0.7, \n",
    "                   label='비이탈 고객', color='skyblue', density=True)\n",
    "    axes[1, 0].hist(y_pred_proba[y_test == 1], bins=30, alpha=0.7, \n",
    "                   label='이탈 고객', color='salmon', density=True)\n",
    "    axes[1, 0].axvline(x=0.5, color='red', linestyle='--', alpha=0.8, label='임계값 0.5')\n",
    "    axes[1, 0].set_xlabel('Predicted Probability')\n",
    "    axes[1, 0].set_ylabel('Density')\n",
    "    axes[1, 0].set_title('Prediction Probability Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 임계값별 성능 변화\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresh = (y_pred_proba >= threshold).astype(int)\n",
    "        if len(np.unique(y_pred_thresh)) == 2:  # 두 클래스 모두 예측된 경우만\n",
    "            prec = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "        else:\n",
    "            prec = rec = f1 = 0\n",
    "        \n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    axes[1, 1].plot(thresholds, precisions, label='Precision', linewidth=2)\n",
    "    axes[1, 1].plot(thresholds, recalls, label='Recall', linewidth=2)\n",
    "    axes[1, 1].plot(thresholds, f1_scores, label='F1-Score', linewidth=2)\n",
    "    axes[1, 1].axvline(x=0.5, color='red', linestyle='--', alpha=0.8, label='Default Threshold')\n",
    "    axes[1, 1].set_xlabel('Threshold')\n",
    "    axes[1, 1].set_ylabel('Score')\n",
    "    axes[1, 1].set_title('Performance vs Threshold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 예측 결과 분포 (실제 vs 예측)\n",
    "    result_df = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred,\n",
    "        'Probability': y_pred_proba\n",
    "    })\n",
    "    \n",
    "    # 성능 매트릭스\n",
    "    metrics_data = {\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'PR-AUC'],\n",
    "        'Score': [accuracy, precision, recall, f1, auc, ap_score]\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    bars = axes[1, 2].bar(metrics_df['Metric'], metrics_df['Score'], \n",
    "                         color=['skyblue', 'lightgreen', 'salmon', 'gold', 'lightcoral', 'plum'])\n",
    "    axes[1, 2].set_ylim(0, 1)\n",
    "    axes[1, 2].set_title('Performance Metrics Summary')\n",
    "    axes[1, 2].set_xlabel('Metrics')\n",
    "    axes[1, 2].set_ylabel('Score')\n",
    "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 막대 위에 값 표시\n",
    "    for bar, score in zip(bars, metrics_df['Score']):\n",
    "        axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                       f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 최적 임계값 찾기 (F1-Score 기준)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    optimal_f1 = f1_scores[optimal_idx]\n",
    "    \n",
    "    print(f\"\\\\n🎯 최적 임계값 분석 (F1-Score 기준):\")\n",
    "    print(f\"  • 최적 임계값: {optimal_threshold:.3f}\")\n",
    "    print(f\"  • 최적 F1-Score: {optimal_f1:.4f}\")\n",
    "    print(f\"  • 현재 임계값 (0.5) F1-Score: {f1:.4f}\")\n",
    "    print(f\"  • 개선 가능성: {optimal_f1 - f1:+.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 실제 라벨이 없어 시각화를 건너뜁니다.\")\n",
    "    \n",
    "print(\"\\n📊 시각화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10df2d4",
   "metadata": {},
   "source": [
    "## 4.5. 모델 해석성 분석\n",
    "\n",
    "모델의 예측 결과를 해석하고 주요 피처들의 중요도를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 모델 해석성 분석\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 모델의 피처 중요도 분석 (트리 기반 모델들)\n",
    "model_name = model_info.get('model_name', 'Unknown Model')\n",
    "print(f\"📋 분석 대상 모델: {model_name}\")\n",
    "\n",
    "# 현재 모델이 피처 중요도를 제공하는지 확인\n",
    "show_feature_importance = False\n",
    "if 'model' in locals() and hasattr(model, 'feature_importances_'):\n",
    "    show_feature_importance = True\n",
    "    print(\"✅ 피처 중요도 정보 사용 가능\")\n",
    "else:\n",
    "    print(\"⚠️ 현재 모델은 피처 중요도를 직접 제공하지 않습니다.\")\n",
    "\n",
    "if show_feature_importance:\n",
    "    try:\n",
    "        # 피처 이름 가져오기\n",
    "        if 'feature_names' in model_info and model_info['feature_names']:\n",
    "            feature_names = model_info['feature_names']\n",
    "        elif hasattr(X_test, 'columns'):\n",
    "            feature_names = list(X_test.columns)\n",
    "        else:\n",
    "            feature_names = [f'feature_{i}' for i in range(len(model.feature_importances_))]\n",
    "        \n",
    "        # 피처 이름과 중요도의 길이를 맞춤\n",
    "        if len(feature_names) != len(model.feature_importances_):\n",
    "            print(f\"⚠️ 피처 이름 수({len(feature_names)})와 중요도 수({len(model.feature_importances_)})가 일치하지 않습니다.\")\n",
    "            feature_names = [f'feature_{i}' for i in range(len(model.feature_importances_))]\n",
    "        \n",
    "        # 피처 중요도 데이터프레임 생성\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "        # 피처 중요도 시각화\n",
    "        print(f\"\\n🌳 피처 중요도 시각화:\")\n",
    "        \n",
    "        # 상위 15개 피처만 표시\n",
    "        top_features = importance_df.tail(15)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        bars = plt.barh(range(len(top_features)), top_features['importance'], \n",
    "                       color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'{model_name} - Top 15 Feature Importances')\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 막대 끝에 값 표시\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            plt.text(width + width*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{width:.4f}', ha='left', va='center', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 상위 10개 중요 피처 출력\n",
    "        print(f\"\\n📊 상위 10개 중요 피처:\")\n",
    "        top_10 = importance_df.tail(10)\n",
    "        for i, (idx, row) in enumerate(top_10.iterrows(), 1):\n",
    "            print(f\"  {i:2d}. {row['feature']:<25}: {row['importance']:.6f}\")\n",
    "        \n",
    "        # 피처 중요도 통계\n",
    "        print(f\"\\n📈 피처 중요도 통계:\")\n",
    "        print(f\"  • 총 피처 수: {len(importance_df)}\")\n",
    "        print(f\"  • 평균 중요도: {importance_df['importance'].mean():.6f}\")\n",
    "        print(f\"  • 중요도 표준편차: {importance_df['importance'].std():.6f}\")\n",
    "        print(f\"  • 상위 10개 피처의 누적 중요도: {top_10['importance'].sum():.3f}\")\n",
    "        print(f\"  • 상위 5개 피처의 누적 중요도: {importance_df.tail(5)['importance'].sum():.3f}\")\n",
    "        \n",
    "        # 중요도 범주별 분석\n",
    "        high_importance = importance_df[importance_df['importance'] > importance_df['importance'].quantile(0.9)]\n",
    "        medium_importance = importance_df[\n",
    "            (importance_df['importance'] > importance_df['importance'].quantile(0.7)) & \n",
    "            (importance_df['importance'] <= importance_df['importance'].quantile(0.9))\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\n🎯 중요도 범주별 분석:\")\n",
    "        print(f\"  • 고중요도 피처 (상위 10%): {len(high_importance)}개\")\n",
    "        print(f\"  • 중간중요도 피처 (70-90%): {len(medium_importance)}개\")\n",
    "        print(f\"  • 저중요도 피처 (하위 70%): {len(importance_df) - len(high_importance) - len(medium_importance)}개\")\n",
    "        \n",
    "        # 고중요도 피처들의 특성 분석\n",
    "        if len(high_importance) > 0:\n",
    "            print(f\"\\n🔥 고중요도 피처 목록:\")\n",
    "            for idx, row in high_importance.iterrows():\n",
    "                print(f\"  • {row['feature']}: {row['importance']:.6f}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 피처 중요도 분석 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        print(f\"상세 오류: {traceback.format_exc()}\")\n",
    "else:\n",
    "    print(f\"\\n💡 대안적 모델 해석 방법:\")\n",
    "    print(f\"  • SHAP (SHapley Additive exPlanations) 값 계산\")\n",
    "    print(f\"  • LIME (Local Interpretable Model-agnostic Explanations)\")\n",
    "    print(f\"  • Permutation Importance 계산\")\n",
    "    print(f\"  • 부분 의존성 플롯 (Partial Dependence Plots)\")\n",
    "\n",
    "print(f\"\\n🔍 모델 해석성 분석 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8689a9",
   "metadata": {},
   "source": [
    "## 5. 비즈니스 임팩트 분석\n",
    "\n",
    "모델의 성능을 실제 비즈니스 관점에서 평가하고 경제적 가치를 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89952261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비즈니스 가정값 설정\n",
    "business_assumptions = {\n",
    "    'avg_customer_value': 1000,      # 고객 평균 생애가치 ($)\n",
    "    'retention_cost': 50,            # 고객 유지 비용 ($)\n",
    "    'acquisition_cost': 200,         # 신규 고객 획득 비용 ($)\n",
    "    'intervention_success_rate': 0.3, # 이탈 방지 캠페인 성공률\n",
    "    'total_customers': 10000         # 전체 고객 수 (예상)\n",
    "}\n",
    "\n",
    "print(\"💼 비즈니스 임팩트 분석\")\n",
    "print(\"=\" * 60)\n",
    "print(\"📋 비즈니스 가정:\")\n",
    "for key, value in business_assumptions.items():\n",
    "    if 'rate' in key:\n",
    "        print(f\"  • {key}: {value:.1%}\")\n",
    "    elif 'cost' in key or 'value' in key:\n",
    "        print(f\"  • {key}: ${value:,}\")\n",
    "    else:\n",
    "        print(f\"  • {key}: {value:,}\")\n",
    "\n",
    "if y_test is not None:\n",
    "    # 혼동 행렬 기반 비즈니스 임팩트 계산\n",
    "    print(f\"\\\\n🎯 예측 성능 기반 비즈니스 시나리오:\")\n",
    "    \n",
    "    # 전체 고객 수로 스케일링\n",
    "    scale_factor = business_assumptions['total_customers'] / len(y_test)\n",
    "    \n",
    "    scaled_tp = int(tp * scale_factor)\n",
    "    scaled_fp = int(fp * scale_factor)\n",
    "    scaled_fn = int(fn * scale_factor)\n",
    "    scaled_tn = int(tn * scale_factor)\n",
    "    \n",
    "    print(f\"\\\\n📊 전체 고객 {business_assumptions['total_customers']:,}명 대상 예상 결과:\")\n",
    "    print(f\"  • 올바른 이탈 예측 (TP): {scaled_tp:,}명\")\n",
    "    print(f\"  • 잘못된 이탈 예측 (FP): {scaled_fp:,}명\")\n",
    "    print(f\"  • 놓친 이탈 고객 (FN): {scaled_fn:,}명\")\n",
    "    print(f\"  • 올바른 유지 예측 (TN): {scaled_tn:,}명\")\n",
    "    \n",
    "    # 비용-편익 분석\n",
    "    # 1. 올바른 이탈 예측 시 비용/편익\n",
    "    prevented_churn = scaled_tp * business_assumptions['intervention_success_rate']\n",
    "    intervention_cost_tp = scaled_tp * business_assumptions['retention_cost']\n",
    "    saved_value_tp = prevented_churn * business_assumptions['avg_customer_value']\n",
    "    \n",
    "    # 2. 잘못된 이탈 예측 시 비용\n",
    "    intervention_cost_fp = scaled_fp * business_assumptions['retention_cost']\n",
    "    \n",
    "    # 3. 놓친 이탈 고객 손실\n",
    "    lost_value_fn = scaled_fn * business_assumptions['avg_customer_value']\n",
    "    replacement_cost_fn = scaled_fn * business_assumptions['acquisition_cost']\n",
    "    \n",
    "    # 총 비용 및 편익\n",
    "    total_intervention_cost = intervention_cost_tp + intervention_cost_fp\n",
    "    total_saved_value = saved_value_tp\n",
    "    total_lost_value = lost_value_fn + replacement_cost_fn\n",
    "    \n",
    "    net_benefit = total_saved_value - total_intervention_cost - total_lost_value\n",
    "    \n",
    "    print(f\"\\\\n💰 경제적 영향 분석:\")\n",
    "    print(f\"\\\\n📈 편익 (수익):\")\n",
    "    print(f\"  • 방지된 이탈 고객: {prevented_churn:.0f}명\")\n",
    "    print(f\"  • 절약된 고객 가치: ${total_saved_value:,.0f}\")\n",
    "    \n",
    "    print(f\"\\\\n📉 비용 (지출):\")\n",
    "    print(f\"  • 이탈 방지 캠페인 비용: ${total_intervention_cost:,.0f}\")\n",
    "    print(f\"    - 올바른 예측 대상: ${intervention_cost_tp:,.0f}\")\n",
    "    print(f\"    - 잘못된 예측 대상: ${intervention_cost_fp:,.0f}\")\n",
    "    print(f\"  • 놓친 이탈로 인한 손실: ${total_lost_value:,.0f}\")\n",
    "    print(f\"    - 고객 가치 손실: ${lost_value_fn:,.0f}\")\n",
    "    print(f\"    - 신규 고객 획득 비용: ${replacement_cost_fn:,.0f}\")\n",
    "    \n",
    "    print(f\"\\\\n🎯 최종 결과:\")\n",
    "    print(f\"  • 순 편익 (Net Benefit): ${net_benefit:,.0f}\")\n",
    "    \n",
    "    if net_benefit > 0:\n",
    "        print(f\"  ✅ 모델 도입 권장! 연간 약 ${net_benefit:,.0f} 절약 예상\")\n",
    "    else:\n",
    "        print(f\"  ⚠️ 모델 개선 필요. 현재 ${abs(net_benefit):,.0f} 손실 예상\")\n",
    "    \n",
    "    # ROI 계산\n",
    "    investment_cost = total_intervention_cost\n",
    "    if investment_cost > 0:\n",
    "        roi = (total_saved_value - investment_cost) / investment_cost * 100\n",
    "        print(f\"  • ROI (투자 수익률): {roi:.1f}%\")\n",
    "    \n",
    "    # 임계값 최적화를 통한 비즈니스 개선 가능성\n",
    "    print(f\"\\\\n🔧 임계값 최적화 권장사항:\")\n",
    "    if optimal_threshold != 0.5:\n",
    "        y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "        cm_optimal = confusion_matrix(y_test, y_pred_optimal)\n",
    "        tn_opt, fp_opt, fn_opt, tp_opt = cm_optimal.ravel()\n",
    "        \n",
    "        # 최적 임계값으로 다시 계산\n",
    "        scaled_tp_opt = int(tp_opt * scale_factor)\n",
    "        scaled_fp_opt = int(fp_opt * scale_factor)\n",
    "        scaled_fn_opt = int(fn_opt * scale_factor)\n",
    "        \n",
    "        prevented_churn_opt = scaled_tp_opt * business_assumptions['intervention_success_rate']\n",
    "        intervention_cost_opt = (scaled_tp_opt + scaled_fp_opt) * business_assumptions['retention_cost']\n",
    "        saved_value_opt = prevented_churn_opt * business_assumptions['avg_customer_value']\n",
    "        lost_value_opt = scaled_fn_opt * (business_assumptions['avg_customer_value'] + business_assumptions['acquisition_cost'])\n",
    "        \n",
    "        net_benefit_opt = saved_value_opt - intervention_cost_opt - lost_value_opt\n",
    "        improvement = net_benefit_opt - net_benefit\n",
    "        \n",
    "        print(f\"  • 최적 임계값 {optimal_threshold:.3f} 적용 시:\")\n",
    "        print(f\"    - 추가 순 편익: ${improvement:,.0f}\")\n",
    "        print(f\"    - 총 순 편익: ${net_benefit_opt:,.0f}\")\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(f\"    ✅ 임계값 조정 권장!\")\n",
    "        else:\n",
    "            print(f\"    ⚠️ 현재 임계값 유지 권장\")\n",
    "    \n",
    "    # 시나리오 분석 시각화\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 비용-편익 분석 차트\n",
    "    categories = ['절약된\\\\n고객 가치', '캠페인\\\\n비용', '놓친 이탈\\\\n손실']\n",
    "    values = [total_saved_value, -total_intervention_cost, -total_lost_value]\n",
    "    colors = ['green', 'orange', 'red']\n",
    "    \n",
    "    bars = axes[0].bar(categories, values, color=colors, alpha=0.7)\n",
    "    axes[0].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    axes[0].set_title('비용-편익 분석')\n",
    "    axes[0].set_ylabel('금액 ($)')\n",
    "    \n",
    "    # 막대 위에 값 표시\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, height + (50000 if height > 0 else -50000), \n",
    "                    f'${abs(value):,.0f}', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                    fontweight='bold')\n",
    "    \n",
    "    # 순 편익 표시\n",
    "    axes[0].text(0.5, 0.95, f'순 편익: ${net_benefit:,.0f}', \n",
    "                transform=axes[0].transAxes, ha='center', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 예측 정확도별 비교\n",
    "    prediction_types = ['올바른 이탈\\\\n예측 (TP)', '잘못된 이탈\\\\n예측 (FP)', \n",
    "                       '놓친 이탈\\\\n고객 (FN)', '올바른 유지\\\\n예측 (TN)']\n",
    "    prediction_counts = [scaled_tp, scaled_fp, scaled_fn, scaled_tn]\n",
    "    prediction_colors = ['darkgreen', 'orange', 'red', 'lightgreen']\n",
    "    \n",
    "    wedges, texts, autotexts = axes[1].pie(prediction_counts, labels=prediction_types, \n",
    "                                          colors=prediction_colors, autopct='%1.1f%%',\n",
    "                                          startangle=90)\n",
    "    axes[1].set_title('예측 결과 분포')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ 실제 라벨이 없어 비즈니스 임팩트 분석을 건너뜁니다.\")\n",
    "\n",
    "print(\"\\\\n💼 비즈니스 분석 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeace7f",
   "metadata": {},
   "source": [
    "## 6. 배포 권장사항\n",
    "\n",
    "모델을 실제 운영 환경에 배포하기 위한 실용적인 가이드라인을 제시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32266bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배포 권장사항 생성\n",
    "deployment_recommendations = {\n",
    "    \"모델 성능\": {\n",
    "        \"현재 성능\": f\"AUC {auc:.3f}, F1-Score {f1:.3f}\" if y_test is not None else \"평가 불가\",\n",
    "        \"권장 임계값\": f\"{optimal_threshold:.3f}\" if y_test is not None else \"0.500\",\n",
    "        \"성능 모니터링\": \"월별 AUC 0.75 이상 유지 필요\"\n",
    "    },\n",
    "    \"비즈니스 가치\": {\n",
    "        \"예상 ROI\": f\"{roi:.1f}%\" if y_test is not None and 'roi' in locals() else \"계산 불가\",\n",
    "        \"순 편익\": f\"${net_benefit:,.0f}\" if y_test is not None and 'net_benefit' in locals() else \"분석 필요\",\n",
    "        \"적용 범위\": \"전체 고객 대상 일괄 적용 권장\"\n",
    "    },\n",
    "    \"운영 고려사항\": {\n",
    "        \"예측 주기\": \"월 1회 배치 처리\",\n",
    "        \"데이터 업데이트\": \"실시간 피처 업데이트 필요\",\n",
    "        \"A/B 테스트\": \"신규 고객 10% 대상 테스트 후 확대\"\n",
    "    },\n",
    "    \"위험 관리\": {\n",
    "        \"모델 드리프트\": \"분기별 재학습 필요\",\n",
    "        \"성능 임계치\": \"AUC 0.70 미만 시 즉시 재학습\",\n",
    "        \"백업 전략\": \"룰 기반 모델 병행 운영\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"🚀 모델 배포 권장사항\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, items in deployment_recommendations.items():\n",
    "    print(f\"\\\\n📋 {category}:\")\n",
    "    for key, value in items.items():\n",
    "        print(f\"  • {key}: {value}\")\n",
    "\n",
    "# 배포 체크리스트\n",
    "deployment_checklist = [\n",
    "    \"✅ 모델 성능 검증 완료\",\n",
    "    \"✅ 비즈니스 케이스 검증 완료\", \n",
    "    \"⚠️ A/B 테스트 계획 수립\",\n",
    "    \"⚠️ 모니터링 시스템 구축\",\n",
    "    \"⚠️ 롤백 계획 수립\",\n",
    "    \"⚠️ 데이터 파이프라인 구축\",\n",
    "    \"⚠️ 성능 대시보드 개발\",\n",
    "    \"⚠️ 운영팀 교육 완료\"\n",
    "]\n",
    "\n",
    "print(f\"\\\\n📝 배포 준비 체크리스트:\")\n",
    "for item in deployment_checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "# 최종 권장사항 요약\n",
    "print(f\"\\\\n🎯 최종 권장사항:\")\n",
    "\n",
    "if y_test is not None:\n",
    "    if auc >= 0.8 and net_benefit > 0:\n",
    "        recommendation = \"즉시 배포 권장\"\n",
    "        urgency = \"🟢 HIGH\"\n",
    "    elif auc >= 0.7 and net_benefit > 0:\n",
    "        recommendation = \"조건부 배포 권장 (A/B 테스트 후)\"\n",
    "        urgency = \"🟡 MEDIUM\"\n",
    "    else:\n",
    "        recommendation = \"모델 개선 후 재평가\"\n",
    "        urgency = \"🔴 LOW\"\n",
    "else:\n",
    "    recommendation = \"실제 데이터로 재평가 필요\"\n",
    "    urgency = \"⚪ PENDING\"\n",
    "\n",
    "print(f\"  • 배포 우선순위: {urgency}\")\n",
    "print(f\"  • 권장사항: {recommendation}\")\n",
    "\n",
    "# 다음 단계\n",
    "next_steps = [\n",
    "    \"1. 실제 프로덕션 데이터로 모델 재검증\",\n",
    "    \"2. A/B 테스트 설계 및 실행 계획 수립\",\n",
    "    \"3. 모델 모니터링 및 알람 시스템 구축\",\n",
    "    \"4. 이탈 방지 캠페인 프로세스 설계\",\n",
    "    \"5. 성과 측정 KPI 및 대시보드 개발\"\n",
    "]\n",
    "\n",
    "print(f\"\\\\n📅 다음 단계:\")\n",
    "for step in next_steps:\n",
    "    print(f\"  {step}\")\n",
    "\n",
    "# 연락처 및 문서화\n",
    "print(f\"\\\\n📄 관련 문서 및 리소스:\")\n",
    "print(f\"  • 모델 저장 위치: /results/models/\")\n",
    "print(f\"  • 학습 노트북: 03_Modeling.ipynb\")\n",
    "print(f\"  • 프로젝트 문서: docs/\")\n",
    "print(f\"  • 기술 문의: 데이터팀\")\n",
    "print(f\"  • 비즈니스 문의: 마케팅팀\")\n",
    "\n",
    "print(f\"\\\\n\" + \"=\"*60)\n",
    "print(f\"🏁 고객 이탈 예측 모델 평가 완료!\")\n",
    "print(f\"📊 평가 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"💡 추가 질문이나 개선사항이 있으시면 프로젝트 팀에 문의해주세요.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abc-bootcamp-FP-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
