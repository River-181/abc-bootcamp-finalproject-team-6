{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf93245c",
   "metadata": {},
   "source": [
    "# 03. 머신러닝 모델링\n",
    "\n",
    "이 노트북에서는 전처리된 데이터를 사용하여 다양한 머신러닝 모델을 구축하고 학습시킵니다.\n",
    "\n",
    "## 🎯 목표\n",
    "- 고객 이탈 예측 모델 개발\n",
    "- 여러 알고리즘 비교 및 성능 평가\n",
    "- 최적 하이퍼파라미터 탐색\n",
    "- 모델 해석 및 피처 중요도 분석\n",
    "- 최종 모델 저장\n",
    "\n",
    "## 📋 모델링 파이프라인\n",
    "1. 데이터 로드 및 확인\n",
    "2. 피처 엔지니어링\n",
    "3. 학습/검증/테스트 데이터 분할\n",
    "4. 베이스라인 모델 구축\n",
    "5. 다양한 알고리즘 시도\n",
    "6. 모델 성능 비교\n",
    "7. 하이퍼파라미터 튜닝\n",
    "8. 최종 모델 선택 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 모델 평가\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                           roc_curve, precision_recall_curve, f1_score, accuracy_score)\n",
    "\n",
    "# 시각화\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# 설정\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be20b37a",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 확인\n",
    "\n",
    "전처리된 데이터를 로드하고 모델링을 위한 준비를 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e16f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터 로드\n",
    "data_path = Path(\"../data/processed\")\n",
    "\n",
    "# 전처리된 데이터가 있는지 확인\n",
    "if (data_path / \"train_features.csv\").exists():\n",
    "    print(\"📊 전처리된 데이터 로드 중...\")\n",
    "    X_train = pd.read_csv(data_path / \"train_features.csv\")\n",
    "    X_test = pd.read_csv(data_path / \"test_features.csv\")\n",
    "    y_train = pd.read_csv(data_path / \"train_target.csv\").values.ravel()\n",
    "    y_test = pd.read_csv(data_path / \"test_target.csv\").values.ravel()\n",
    "    \n",
    "    print(f\"✅ 전처리된 데이터 로드 완료!\")\n",
    "    print(f\"• 학습 데이터: {X_train.shape}\")\n",
    "    print(f\"• 테스트 데이터: {X_test.shape}\")\n",
    "    print(f\"• 타겟 분포 (학습): {np.unique(y_train, return_counts=True)}\")\n",
    "    \n",
    "else:\n",
    "    # 전처리된 데이터가 없으면 EDA 데이터를 사용\n",
    "    print(\"⚠️ 전처리된 데이터를 찾을 수 없습니다. EDA 데이터를 사용합니다.\")\n",
    "    print(\"💡 02_Preprocessing.ipynb를 먼저 실행하는 것을 권장합니다.\")\n",
    "    \n",
    "    # EDA에서 생성한 데이터 로드\n",
    "    if (data_path / \"customer_data_with_eda_features.csv\").exists():\n",
    "        df = pd.read_csv(data_path / \"customer_data_with_eda_features.csv\")\n",
    "        print(f\"📊 EDA 데이터 로드: {df.shape}\")\n",
    "    else:\n",
    "        # 샘플 데이터 재생성\n",
    "        print(\"🔄 샘플 데이터 생성 중...\")\n",
    "        np.random.seed(RANDOM_STATE)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        sample_data = {\n",
    "            'customer_id': range(1, n_samples + 1),\n",
    "            'age': np.random.normal(35, 12, n_samples).astype(int),\n",
    "            'income': np.random.lognormal(10.5, 0.5, n_samples).astype(int),\n",
    "            'spending_score': np.random.beta(2, 5, n_samples) * 100,\n",
    "            'tenure_months': np.random.exponential(24, n_samples).astype(int),\n",
    "            'num_purchases': np.random.poisson(15, n_samples),\n",
    "            'category': np.random.choice(['Premium', 'Standard', 'Basic'], n_samples, p=[0.2, 0.5, 0.3]),\n",
    "            'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),\n",
    "            'is_churned': np.random.choice([0, 1], n_samples, p=[0.8, 0.2])\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(sample_data)\n",
    "        df['age'] = np.clip(df['age'], 18, 80)\n",
    "        df['income'] = np.clip(df['income'], 20000, 200000)\n",
    "        \n",
    "        print(f\"✅ 샘플 데이터 생성 완료: {df.shape}\")\n",
    "\n",
    "print(f\"\\n📋 데이터 기본 정보:\")\n",
    "if 'df' in locals():\n",
    "    print(df.info())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc883d0",
   "metadata": {},
   "source": [
    "## 2. 피처 엔지니어링 및 데이터 준비\n",
    "\n",
    "모델링을 위한 피처 엔지니어링과 데이터 전처리를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99732f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 데이터가 없는 경우를 위한 피처 엔지니어링\n",
    "if 'df' in locals():\n",
    "    print(\"🔧 피처 엔지니어링 수행 중...\")\n",
    "    \n",
    "    # 1. 결측값 처리\n",
    "    df['income'].fillna(df['income'].median(), inplace=True)\n",
    "    \n",
    "    # 2. 새로운 피처 생성\n",
    "    df['income_per_age'] = df['income'] / df['age']\n",
    "    df['spending_per_tenure'] = df['spending_score'] / (df['tenure_months'] + 1)\n",
    "    df['purchases_per_month'] = df['num_purchases'] / (df['tenure_months'] + 1)\n",
    "    \n",
    "    # 3. 나이 그룹 생성\n",
    "    df['age_group'] = pd.cut(df['age'], \n",
    "                            bins=[0, 25, 35, 45, 55, 100], \n",
    "                            labels=['18-25', '26-35', '36-45', '46-55', '56+'])\n",
    "    \n",
    "    # 4. 소득 구간 생성\n",
    "    df['income_level'] = pd.cut(df['income'], \n",
    "                               bins=[0, 40000, 70000, 100000, float('inf')], \n",
    "                               labels=['Low', 'Medium', 'High', 'Premium'])\n",
    "    \n",
    "    print(\"✅ 피처 엔지니어링 완료!\")\n",
    "    print(f\"• 새로운 피처 개수: 5개\")\n",
    "    print(f\"• 최종 데이터 크기: {df.shape}\")\n",
    "    \n",
    "    # 범주형 변수 인코딩\n",
    "    print(\"\\n🏷️ 범주형 변수 인코딩 중...\")\n",
    "    categorical_columns = ['category', 'region', 'age_group', 'income_level']\n",
    "    \n",
    "    # LabelEncoder 사용\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # 원-핫 인코딩\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_columns, prefix=categorical_columns)\n",
    "    \n",
    "    print(f\"✅ 인코딩 완료! 최종 피처 수: {df_encoded.shape[1]}\")\n",
    "    \n",
    "    # 타겟 변수와 피처 분리\n",
    "    target_col = 'is_churned'\n",
    "    feature_cols = [col for col in df_encoded.columns if col not in [\n",
    "        'customer_id', target_col, 'category', 'region', 'age_group', 'income_level'\n",
    "    ]]\n",
    "    \n",
    "    X = df_encoded[feature_cols]\n",
    "    y = df_encoded[target_col]\n",
    "    \n",
    "    print(f\"\\n📊 최종 데이터 준비:\")\n",
    "    print(f\"• 피처 수: {X.shape[1]}\")\n",
    "    print(f\"• 샘플 수: {X.shape[0]}\")\n",
    "    print(f\"• 타겟 분포: {y.value_counts().to_dict()}\")\n",
    "    \n",
    "    # 학습/테스트 데이터 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n🔄 데이터 분할 완료:\")\n",
    "    print(f\"• 학습 데이터: {X_train.shape}\")\n",
    "    print(f\"• 테스트 데이터: {X_test.shape}\")\n",
    "\n",
    "# 피처 스케일링\n",
    "print(\"\\n⚖️ 피처 스케일링 수행 중...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✅ 스케일링 완료!\")\n",
    "print(f\"• 학습 데이터 평균: {X_train_scaled.mean():.4f}\")\n",
    "print(f\"• 학습 데이터 표준편차: {X_train_scaled.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85533a",
   "metadata": {},
   "source": [
    "## 3. 베이스라인 모델 구축\n",
    "\n",
    "간단한 베이스라인 모델을 구축하여 기준 성능을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이스라인 모델 - 다수 클래스 예측\n",
    "from collections import Counter\n",
    "\n",
    "print(\"📊 베이스라인 모델 평가\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. 다수 클래스 예측 (Majority Class Baseline)\n",
    "majority_class = Counter(y_train).most_common(1)[0][0]\n",
    "y_pred_baseline = np.full(len(y_test), majority_class)\n",
    "\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"🎯 다수 클래스 베이스라인 정확도: {baseline_accuracy:.4f}\")\n",
    "\n",
    "# 2. 로지스틱 회귀 베이스라인\n",
    "print(\"\\n🤖 로지스틱 회귀 베이스라인\")\n",
    "lr_baseline = LogisticRegression(random_state=RANDOM_STATE)\n",
    "lr_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = lr_baseline.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_baseline.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(f\"• 정확도: {lr_accuracy:.4f}\")\n",
    "print(f\"• F1-Score: {lr_f1:.4f}\")\n",
    "print(f\"• AUC-ROC: {lr_auc:.4f}\")\n",
    "\n",
    "# 베이스라인 성능 저장\n",
    "baseline_results = {\n",
    "    'majority_class_accuracy': baseline_accuracy,\n",
    "    'logistic_regression': {\n",
    "        'accuracy': lr_accuracy,\n",
    "        'f1_score': lr_f1,\n",
    "        'auc_roc': lr_auc\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ 베이스라인 모델 평가 완료!\")\n",
    "print(f\"💡 목표: AUC-ROC > {lr_auc:.4f}, F1-Score > {lr_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bdb0e6",
   "metadata": {},
   "source": [
    "## 4. 다양한 알고리즘 비교\n",
    "\n",
    "여러 머신러닝 알고리즘을 시도하고 성능을 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True, random_state=RANDOM_STATE),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"🤖 다양한 모델 성능 비교\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 교차 검증을 위한 설정\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "# 각 모델 평가\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n📊 {name} 평가 중...\")\n",
    "    \n",
    "    # 교차 검증\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    # 모델 학습 및 예측\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # 성능 지표 계산\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'cv_auc_mean': cv_scores.mean(),\n",
    "        'cv_auc_std': cv_scores.std(),\n",
    "        'test_accuracy': accuracy,\n",
    "        'test_f1': f1,\n",
    "        'test_auc': auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"  • CV AUC: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
    "    print(f\"  • Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  • Test F1-Score: {f1:.4f}\")\n",
    "    if auc is not None:\n",
    "        print(f\"  • Test AUC: {auc:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 모델 비교 완료!\")\n",
    "\n",
    "# 결과 정리\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'CV_AUC_Mean': [results[model]['cv_auc_mean'] for model in results],\n",
    "    'CV_AUC_Std': [results[model]['cv_auc_std'] for model in results],\n",
    "    'Test_Accuracy': [results[model]['test_accuracy'] for model in results],\n",
    "    'Test_F1': [results[model]['test_f1'] for model in results],\n",
    "    'Test_AUC': [results[model]['test_auc'] if results[model]['test_auc'] is not None else np.nan for model in results]\n",
    "})\n",
    "\n",
    "comparison_df = comparison_df.sort_values('CV_AUC_Mean', ascending=False)\n",
    "print(f\"\\n📊 모델 성능 순위:\")\n",
    "display(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213dea07",
   "metadata": {},
   "source": [
    "## 5. 하이퍼파라미터 튜닝\n",
    "\n",
    "상위 성능 모델들에 대해 GridSearchCV를 사용하여 최적 하이퍼파라미터를 찾아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 3개 모델 선택\n",
    "top_models = comparison_df.head(3)['Model'].tolist()\n",
    "print(f\"🎯 하이퍼파라미터 튜닝 대상 모델: {top_models}\")\n",
    "\n",
    "# 하이퍼파라미터 그리드 정의\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 10, 20],\n",
    "        'min_samples_leaf': [1, 2, 5, 10],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 튜닝된 모델 저장\n",
    "best_models = {}\n",
    "tuning_results = {}\n",
    "\n",
    "print(\"\\n🔧 하이퍼파라미터 튜닝 시작...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_name in top_models:\n",
    "    if model_name in param_grids:\n",
    "        print(f\"\\n🎛️ {model_name} 튜닝 중...\")\n",
    "        \n",
    "        # 원본 모델 가져오기\n",
    "        original_model = models[model_name]\n",
    "        \n",
    "        # GridSearch 설정\n",
    "        grid_search = GridSearchCV(\n",
    "            original_model,\n",
    "            param_grids[model_name],\n",
    "            cv=3,  # 시간 절약을 위해 3-fold\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # 튜닝 실행\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # 최적 모델로 예측\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred_tuned = best_model.predict(X_test_scaled)\n",
    "        y_pred_proba_tuned = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # 성능 계산\n",
    "        tuned_accuracy = accuracy_score(y_test, y_pred_tuned)\n",
    "        tuned_f1 = f1_score(y_test, y_pred_tuned)\n",
    "        tuned_auc = roc_auc_score(y_test, y_pred_proba_tuned)\n",
    "        \n",
    "        # 결과 저장\n",
    "        best_models[model_name] = best_model\n",
    "        tuning_results[model_name] = {\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_cv_score': grid_search.best_score_,\n",
    "            'test_accuracy': tuned_accuracy,\n",
    "            'test_f1': tuned_f1,\n",
    "            'test_auc': tuned_auc,\n",
    "            'tuning_time': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        # 개선 정도 계산\n",
    "        original_auc = results[model_name]['test_auc']\n",
    "        improvement = tuned_auc - original_auc if original_auc else 0\n",
    "        \n",
    "        print(f\"  ✅ 완료! 소요시간: {end_time - start_time:.2f}초\")\n",
    "        print(f\"  • 최적 파라미터: {grid_search.best_params_}\")\n",
    "        print(f\"  • CV Score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"  • Test AUC: {tuned_auc:.4f} (개선: {improvement:+.4f})\")\n",
    "        print(f\"  • Test Accuracy: {tuned_accuracy:.4f}\")\n",
    "        print(f\"  • Test F1-Score: {tuned_f1:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 하이퍼파라미터 튜닝 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d397e",
   "metadata": {},
   "source": [
    "## 6. 모델 성능 시각화\n",
    "\n",
    "다양한 시각화를 통해 모델들의 성능을 비교해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889eb9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ROC 곡선 비교\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 첫 번째 서브플롯: 모든 모델 ROC 곡선\n",
    "plt.subplot(1, 3, 1)\n",
    "for name, result in results.items():\n",
    "    if result['y_pred_proba'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
    "        auc_score = result['test_auc']\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.500)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Original Models')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 두 번째 서브플롯: 성능 지표 비교 (막대 그래프)\n",
    "plt.subplot(1, 3, 2)\n",
    "metrics = ['test_accuracy', 'test_f1', 'test_auc']\n",
    "metric_names = ['Accuracy', 'F1-Score', 'AUC']\n",
    "colors = ['skyblue', 'lightgreen', 'salmon']\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.25\n",
    "\n",
    "for i, (metric, name, color) in enumerate(zip(metrics, metric_names, colors)):\n",
    "    values = [results[model][metric] if results[model][metric] is not None else 0 \n",
    "              for model in comparison_df['Model']]\n",
    "    plt.bar(x + i*width, values, width, label=name, color=color, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Metrics Comparison')\n",
    "plt.xticks(x + width, comparison_df['Model'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 세 번째 서브플롯: 교차검증 점수 분포\n",
    "plt.subplot(1, 3, 3)\n",
    "cv_means = [results[model]['cv_auc_mean'] for model in comparison_df['Model']]\n",
    "cv_stds = [results[model]['cv_auc_std'] for model in comparison_df['Model']]\n",
    "\n",
    "plt.errorbar(range(len(cv_means)), cv_means, yerr=cv_stds, \n",
    "             fmt='o', capsize=5, capthick=2, elinewidth=2, markerfacecolor='orange', \n",
    "             markeredgecolor='red', markeredgewidth=2, markersize=8)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Cross-Validation AUC')\n",
    "plt.title('CV Performance with Error Bars')\n",
    "plt.xticks(range(len(comparison_df)), comparison_df['Model'], rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. 혼동 행렬 히트맵 (상위 3개 모델)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "fig.suptitle('Confusion Matrices - Top 3 Models', fontsize=16, y=1.02)\n",
    "\n",
    "for i, model_name in enumerate(top_models[:3]):\n",
    "    if model_name in results:\n",
    "        y_pred = results[model_name]['y_pred']\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['No Churn', 'Churn'],\n",
    "                   yticklabels=['No Churn', 'Churn'],\n",
    "                   ax=axes[i])\n",
    "        axes[i].set_title(f'{model_name}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. 피처 중요도 시각화 (트리 기반 모델들)\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'Decision Tree']\n",
    "available_tree_models = [model for model in tree_models if model in results]\n",
    "\n",
    "if available_tree_models:\n",
    "    fig, axes = plt.subplots(len(available_tree_models), 1, figsize=(12, 6*len(available_tree_models)))\n",
    "    if len(available_tree_models) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, model_name in enumerate(available_tree_models):\n",
    "        model = results[model_name]['model']\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=True)\n",
    "            \n",
    "            # 상위 10개 피처만 표시\n",
    "            top_features = importance_df.tail(10)\n",
    "            \n",
    "            axes[i].barh(range(len(top_features)), top_features['importance'])\n",
    "            axes[i].set_yticks(range(len(top_features)))\n",
    "            axes[i].set_yticklabels(top_features['feature'])\n",
    "            axes[i].set_xlabel('Feature Importance')\n",
    "            axes[i].set_title(f'{model_name} - Top 10 Feature Importances')\n",
    "            axes[i].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"📊 시각화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5515b",
   "metadata": {},
   "source": [
    "## 7. 최종 모델 선택 및 저장\n",
    "\n",
    "성능 평가 결과를 바탕으로 최적의 모델을 선택하고 저장하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d464eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 선택\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_auc_score = comparison_df.iloc[0]['CV_AUC_Mean']\n",
    "\n",
    "print(f\"🏆 최고 성능 모델: {best_model_name}\")\n",
    "print(f\"📊 교차검증 AUC: {best_auc_score:.4f}\")\n",
    "\n",
    "# 하이퍼파라미터 튜닝된 모델이 있다면 사용\n",
    "if best_model_name in best_models:\n",
    "    final_model = best_models[best_model_name]\n",
    "    tuned_results = tuning_results[best_model_name]\n",
    "    print(f\"🎛️ 하이퍼파라미터 튜닝 적용됨\")\n",
    "    print(f\"  • 최적 파라미터: {tuned_results['best_params']}\")\n",
    "    print(f\"  • 튜닝된 Test AUC: {tuned_results['test_auc']:.4f}\")\n",
    "else:\n",
    "    final_model = results[best_model_name]['model']\n",
    "    print(f\"⚙️ 기본 파라미터 사용\")\n",
    "\n",
    "# 최종 성능 평가\n",
    "y_final_pred = final_model.predict(X_test_scaled)\n",
    "y_final_proba = final_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "final_accuracy = accuracy_score(y_test, y_final_pred)\n",
    "final_precision = precision_score(y_test, y_final_pred)\n",
    "final_recall = recall_score(y_test, y_final_pred)\n",
    "final_f1 = f1_score(y_test, y_final_pred)\n",
    "final_auc = roc_auc_score(y_test, y_final_proba)\n",
    "\n",
    "print(f\"\\n📈 최종 모델 성능:\")\n",
    "print(f\"  • Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"  • Precision: {final_precision:.4f}\")\n",
    "print(f\"  • Recall: {final_recall:.4f}\")\n",
    "print(f\"  • F1-Score: {final_f1:.4f}\")\n",
    "print(f\"  • AUC: {final_auc:.4f}\")\n",
    "\n",
    "# 모델과 전처리기 저장\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# 결과 폴더 생성\n",
    "models_dir = '../results/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# 현재 시간으로 파일명 생성\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'best_model_{best_model_name.lower().replace(\" \", \"_\")}_{timestamp}.pkl'\n",
    "scaler_filename = f'scaler_{timestamp}.pkl'\n",
    "results_filename = f'model_results_{timestamp}.pkl'\n",
    "\n",
    "# 모델 저장\n",
    "model_path = os.path.join(models_dir, model_filename)\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# 스케일러 저장\n",
    "scaler_path = os.path.join(models_dir, scaler_filename)\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# 결과 정보 저장\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'model_path': model_path,\n",
    "    'scaler_path': scaler_path,\n",
    "    'feature_names': feature_names,\n",
    "    'performance': {\n",
    "        'accuracy': final_accuracy,\n",
    "        'precision': final_precision,\n",
    "        'recall': final_recall,\n",
    "        'f1_score': final_f1,\n",
    "        'auc': final_auc\n",
    "    },\n",
    "    'hyperparameters': tuned_results['best_params'] if best_model_name in best_models else 'default',\n",
    "    'training_date': timestamp,\n",
    "    'model_comparison': comparison_df.to_dict('records')\n",
    "}\n",
    "\n",
    "results_path = os.path.join(models_dir, results_filename)\n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "\n",
    "print(f\"\\n💾 모델 저장 완료:\")\n",
    "print(f\"  • 모델: {model_path}\")\n",
    "print(f\"  • 스케일러: {scaler_path}\")\n",
    "print(f\"  • 결과 정보: {results_path}\")\n",
    "\n",
    "# 간단한 모델 요약 저장 (읽기 쉬운 텍스트 형태)\n",
    "summary_filename = f'model_summary_{timestamp}.txt'\n",
    "summary_path = os.path.join(models_dir, summary_filename)\n",
    "\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"고객 이탈 예측 모델 - 최종 결과 보고서\\n\")\n",
    "    f.write(f\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"모델명: {best_model_name}\\n\")\n",
    "    f.write(f\"학습일시: {timestamp}\\n\\n\")\n",
    "    f.write(f\"성능 지표:\\n\")\n",
    "    f.write(f\"  - Accuracy: {final_accuracy:.4f}\\n\")\n",
    "    f.write(f\"  - Precision: {final_precision:.4f}\\n\")\n",
    "    f.write(f\"  - Recall: {final_recall:.4f}\\n\")\n",
    "    f.write(f\"  - F1-Score: {final_f1:.4f}\\n\")\n",
    "    f.write(f\"  - AUC: {final_auc:.4f}\\n\\n\")\n",
    "    \n",
    "    if best_model_name in best_models:\n",
    "        f.write(f\"최적화된 하이퍼파라미터:\\n\")\n",
    "        for param, value in tuned_results['best_params'].items():\n",
    "            f.write(f\"  - {param}: {value}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n모델 비교 결과:\\n\")\n",
    "    for idx, row in comparison_df.iterrows():\n",
    "        f.write(f\"  {idx+1}. {row['Model']}: AUC {row['CV_AUC_Mean']:.4f}\\n\")\n",
    "\n",
    "print(f\"  • 요약 보고서: {summary_path}\")\n",
    "print(f\"\\n✅ 모델링 프로세스 완료! 다음 단계: 04_Evaluation.ipynb에서 상세 평가 진행\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
